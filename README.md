# Kiel City Data Platform - Cloud Computing Orchestration Example

A comprehensive example of an orchestrated cloud computing application showcasing API development, multiple database systems, caching, and data visualization.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kiel City Data Platform                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit      â”‚      â”‚    FastAPI       â”‚      â”‚   Cron Job       â”‚
â”‚   Dashboard      â”‚â”€â”€â”€â”€â”€â–¶â”‚    Backend       â”‚      â”‚   (Bike Sync)    â”‚
â”‚   Port: 8501     â”‚      â”‚    Port: 8000    â”‚      â”‚   Every 5 min    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚              â”‚              â”‚
                    â–¼              â–¼              â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Redis     â”‚  â”‚ MySQL  â”‚  â”‚   MongoDB   â”‚
          â”‚   Cache     â”‚  â”‚  Kiel Data  â”‚  â”‚  Bike Data  â”‚
          â”‚  Port: 6379 â”‚  â”‚ Port: 3306  â”‚  â”‚ Port: 27017 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–²
                                   â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Data Loader   â”‚
                          â”‚  (Init Script) â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Features & Rubric Coverage

### Mandatory Requirements âœ…

- **API Implementation (10 points)**
  - FastAPI with POST endpoints (create bike station, add city POI)
  - FastAPI with GET endpoints (list stations, get city data, search)

- **Documentation (5 points)**
  - Interactive Swagger UI at `http://localhost:8000/docs`
  - Comprehensive code documentation with docstrings
  - This README with setup instructions

- **Database (5 points)**
  - MySQL for structured city data
  - MongoDB for bike-sharing time-series data
  - Redis for caching frequently accessed data

- **Data Processing Client (5 points + 5 bonus points)**
  - Interactive Streamlit dashboard
  - Map visualization of Kiel with data overlays
  - Real-time bike availability display
  - Additionally data-loader container

- **Container Deployment (5 points)**
  - Docker Compose orchestration
  - 6 separate containers working together
  - Automated initialization and cron jobs

### Bonus Features ğŸŒŸ

- **Pydantic Data Classes (~5 points)**: Type-safe API models
- **Security Best Practices (~5 points)**: `.env` file, no hardcoded secrets
- **Additional Endpoints (~10 points)**: Batch operations, search, filtering
- **NoSQL with Good Reason (~15 points)**: MongoDB for time-series bike data
- **Redis Caching (~5 points)**: Performance optimization
- **Multiple Database SDKs**: mysql-connector-python (SQL) and pymongo (MongoDB) examples

**Total Points: 30 base + 45 bonus = 75 points (before presentation)**

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose installed
- Internet connection (for fetching bike data)

### Running the System

1. **Clone and navigate to the project**:
   ```bash
   cd cloud_computing_orchestrated_example
   ```

2. **Copy environment template**:
   ```bash
   cp .env.example .env
   # Edit .env if needed (defaults work out of the box)
   ```

3. **Start all services**:
   ```bash
   docker-compose up --build
   ```

4. **Wait for initialization** (~30 seconds):
   - MySQL will be populated with Kiel city data
   - MongoDB will start collecting bike-sharing data
   - All services will become available

5. **Access the applications**:
   - **Dashboard**: http://localhost:8501
   - **API Documentation**: http://localhost:8000/docs
   - **API Base**: http://localhost:8000

### Stopping the System

```bash
docker-compose down
```

To remove all data volumes:
```bash
docker-compose down -v
```

## ğŸ”§ Project Structure

```
.
â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py            # API entry point
â”‚   â”œâ”€â”€ models.py          # Pydantic models
â”‚   â”œâ”€â”€ database.py        # Database connections
â”‚   â”œâ”€â”€ requirements.txt   # Python dependencies
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ dashboard/             # Streamlit visualization
â”‚   â”œâ”€â”€ app.py            # Dashboard code
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ data-loader/          # MySQL initialization
â”‚   â”œâ”€â”€ load_kiel_data.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ cron-job/             # Bike data sync
â”‚   â”œâ”€â”€ fetch_bikes.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ crontab
â”œâ”€â”€ docker-compose.yml    # Orchestration
â”œâ”€â”€ .env.example          # Environment template
â””â”€â”€ README.md
```

## ğŸ¤ Contributing

This is an example project for educational purposes. Feel free to fork and extend!
